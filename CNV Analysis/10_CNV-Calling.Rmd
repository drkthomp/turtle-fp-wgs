---
title: "CNV Analysis"
output: html_notebook
editor_options: 
  chunk_output_type: inline
---
```{r Preset, warning=TRUE, include=FALSE}
library(cn.mops)
library(GenomicRanges)
library(tidyverse)
library(janitor)
library(GenomicFeatures)

setwd("~/2021-REU/CNV Analysis")

# determine whether to use files already generated  
reuse <- TRUE 
```

# CNV Calling 

## Defining Parameters 

First we load the matched tumor and normal data that we're working with. 
```{r Loading Sample Data}
if(file.exists("partials/sample_data") && reuse){
  message("Sample data file exists, loading.")
  # if we've already done this, just load it 
  load("partials/sample_data")
} else {
  message("Generating sample data file.")
sample_data <-
  read.delim("~/2021-REU/Genomic_Samples_Table.xlsx - Sheet1.tsv") %>% clean_names() %>% mutate(sample_name = str_replace_all(sample_name, " - HiSeq", "")) %>% filter(type == "New")

# correct column names
names(sample_data)[names(sample_data) == 'internal_external'] <-
  'tumor_src'
names(sample_data)[names(sample_data) == 'tumor_non_tumor'] <-
  'tissue_status'

# and STATICALLY correct Yucca's kidneys to be analyzed seperately
sample_data <-
  sample_data %>% mutate(turtle = case_when((turtle == 'Yucca' &
                                               tumor_sample_location == 'kidney ') ~ "Yucca_kidney",
                                            TRUE ~ turtle
  ))


# create only the match data for turtle, tumor, and non-tumor
match_data  <- sample_data %>%
  pivot_wider(names_from = tissue_status,
              values_from = sample_name,
              id_cols = turtle) %>% unnest(c(tumor, 'non-tumor'))
# and correct the non-tumor to a more tidy normal
names(match_data)[names(match_data) == 'non-tumor'] <- 'normal'

# then combine the data for easy iteration
sample_data <-
  left_join(sample_data %>% filter(tissue_status == 'tumor'), match_data, by = c("sample_name" = "tumor")) %>% select(-"turtle.y") %>%  distinct()

# and save it for use in other scripts for simplicity
  save(sample_data,"partials/sample_data")
}

```

We can then note relevant settings 
```{r Settings}
dataloc <- 'readcounts/' # note where the readcounts are
bp <- 5000  # then bp we're using
# and the final file name before the tumor:
file_prefix <- paste0(dataloc, "readcounts_",bp,"BP_")
```

and get the relevant reference data 
```{r Genome Reference}
txdb <- loadDb("rCheMyd1.sqlite") # generated from rCheMyd1 
ref <- getChromInfoFromNCBI("GCF_015237465.1",assembled.molecules.only=TRUE,assembly.units = "Primary Assembly")
ref_seq <- getChromInfoFromNCBI("GCF_015237465.1",as.Seqinfo=TRUE,assembled.molecules.only=TRUE,assembly.units = "Primary Assembly")
seqnames(ref_seq) <- ref$RefSeqAccn
```
## Loading data 

**For each paired tumor and normal** we'll then: 
```{r, eval=FALSE}
tum <- x[names(x) == 'sample_name']
normal <- x[names(x) == 'normal']
tum_name <- str_replace(tum, "_", "-")
```
### Read in the read counts 
```{r Read In}
tumors <- c()
read_in <- function(x) {
  tumor_file <-
    paste0(file_prefix, x[names(x) == 'sample_name'], '.txt')
  normal_file <-
    paste0(file_prefix, x[names(x) == 'normal'], '.txt')

  message(paste("Reading in",tumor_file,"and",normal_file))

  # make sure that we've actually downloaded the files
  if (file.exists(tumor_file) && file.exists(normal_file)) {
    tumor <-
      read.table(
        tumor_file,
        header = T,
        strip.white = T,
        check.names = F,
        sep = '\t'
      )
    normal <-
      read.table(
        normal_file,
        header = T,
        strip.white = T,
        check.names = F,
        sep = '\t'
      )

    # and now append host
    result <- left_join(
      tumor,
      normal,
      suffix = c("_TUMOR", "_NORMAL"),
      by = c("SCAFFOLD", "START", "END")
    )
    colnames(result)[4:5] <- c('TUMOUR', 'HOST')
    type_convert(result)

    # dropping the mitochondria mapping here
    result <-
      result %>% filter(SCAFFOLD %in% ref$RefSeqAccn) %>% mutate(SCAFFOLD = as.factor(SCAFFOLD))

    final <-
      makeGRangesFromDataFrame(result,
                               seqnames.field = "SCAFFOLD",
                               keep.extra.columns = TRUE)
    seqinfo(final) <- ref_seq # update the seqinfo with the relevant genome info
    tumors <<-
      c(tumors, as.character(str_replace_all(x[names(x) == 'sample_name'], "-", "_")))

    return(final)
  }
}
```
```{r Running Read in, eval=FALSE}
gr <- read_in(x)
```
### Normalize the data
```{r Normalization, eval=FALSE}
    print(paste0("=== NORMALIZING FOR TUMOR ", tum))
    norm <- normalizeGenome(gr,sizeFactor = "median")
    # and save the call for future use
    #save(norm, file=paste0("partials/normalized/",tum,"-",normal,".gz"),compress=TRUE)
```

### Call The Counts
```{r Call CNV Counts}
# wrapper function to call segmentation
callCounts <- function(norm) {
  segmented <- referencecn.mops(
    cases = norm[, 'TUMOUR'],
    controls = norm[, 'HOST'],
    minReadCount = minReadCount,
    segAlgorithm = 'fast'
  )
  return(calcIntegerCopyNumbers(segmented))
}
```
```{r Call Counts, eval=FALSE}
    print(paste0("=== CALLING FOR TUMOR ", tum))
    segmented <- callCounts(norm)
    # and save the call for future use
    save(segmented, file=paste0("partials/segmented/",tum,"-",normal,".gz"),compress=TRUE)
```

We can then process images based on those counts. 

### Actual Run 
```{r}
normTypes <- c("poisson", "mode", "mean","min","median","quant")
sizeFactors <- c("mean", "median", "mode", "quant")
minReadCounts <- c(4,8,10,16,20,32)

partloc <- paste0("partials/segmented/",bp, "/")
plotloc <- paste0("01_CNV-Plots/", bp,"/")
dir.create(partloc)
dir.create(plotloc)
cnvAnalysis <- function(x) {
  tum <- x[names(x) == 'sample_name']
  normal <- x[names(x) == 'normal']
  tum_name <- str_replace(tum, "_", "-")
  norm_file <- paste0(partloc,normType, "/",sizeFactor,"-", tum,"-",normal,".gz")
  segmented_file <- paste0(partloc, normType, "/",sizeFactor,"-",minReadCount,"-", tum,"-",normal,".gz")
  chromplot_file <- paste0(plotloc, normType, "-", sizeFactor, "-", minReadCount, "-",
                  tum,
                  ' FP - chromosome segplot.png')
  segplot_file <- paste0(plotloc, normType, "-", sizeFactor, "-", minReadCount, "-",
                  tum,
                  ' FP - segplot.pdf')
  if(reuse && file.exists(norm_file) && file.exists(segmented_file) && file.exists(chromplot_file) && file.exists(segplot_file)){
    message(paste("All files exists for tumor",tum, "-- ending generation."))
  }
  else {

  # Read in
  gr <- read_in(x)
  if (!is.null(gr)) { # ensure that we can proceed
    if(reuse && file.exists(norm_file)){
      message(paste("Normalization file exists for tumor",tum))
      load(norm_file)
    } else {
      message(paste("=== NORMALIZING FOR TUMOR", tum))
    norm <- normalizeGenome(gr,sizeFactor = sizeFactor, normType=normType)
    # and save the call for future use
    save(norm, file=norm_file,compress=TRUE)
    }

    
    if(reuse && file.exists(segmented_file)){
      message(paste("Segmentation file exists for tumor",tum))
      load(segmented_file)
    }
    else {
    # Call counts
    message(paste("=== CALLING FOR TUMOR", tum))
    segmented <- callCounts(norm)
    # and save the call for future use
    save(segmented, file=segmented_file,compress=TRUE)
    }
    
    
    if(!(reuse &&file.exists(chromplot_file))){
      message("Generating chromosome plot at ", chromplot_file)
      png(
    file = chromplot_file,
    width = 3000,
    height = 1500
  )
  segplot(
    segmented,
    ylim = c(-5, 5),
    plot.type = "s"
  )
  dev.off()
    }
    if(!(reuse && file.exists(segplot_file))){
      message("Generating chromosome plot at ", segplot_file)
      pdf(segplot_file,
    width = 18,
    height
    = 9)
  segplot(
    segmented,
    ylim = c(-5, 5),
    plot.type = "w",
    pt.cols=c("#333333","#000000")
  )
  dev.off()
      
    }
    

  # cn.mops style segmentation graph
  
  }
  else {
    message("ERROR: Couldn't find read counts file for ", tum)
  }
  }
}
for(normType in normTypes){
  dir.create(paste0(partloc, "/", normType))
  for(sizeFactor in sizeFactors){
    for(minReadCount in minReadCounts){
      message(paste(normType, sizeFactor,minReadCount))
      apply(sample_data, 1, cnvAnalysis)
    }
  }
}

gc()
```
## Analysis 
Thereâ€™s definitely two samples (animals 27 & Poppy) with a full chr.14 gain, worth following up on - especially if these turn out to be recurrent events.

### 27-2017-Cm 
```{r echo=FALSE}
include_graphics(paste0(plotloc, "/","27L1Fdna FP - chromosome segplot.png"))
```
 27-2017-Cm lung FP, whole chromosome 14 amplification, signal = clean
 
### Poppy 
```{r echo=FALSE}
include_graphics(paste0(plotloc, "/","poSCTFdna FP - chromosome segplot.png"))
```
- Poppy FP, whole chromosome 4 and 14 amplifications, subclonal or low purity, signal = clean

### Aladar
```{r echo=FALSE}
include_graphics(paste0(plotloc, "/","TABT-Cm FP - chromosome segplot.png"))
```
- Aladar bladder FP, possibly a few losses (e.g. end of chr5, two small ones on chr7, early chr12, end of chr13), however signal = noisy, particularly at ends of smaller chromosomes

### Yucca 
```{r echo=FALSE}
include_graphics(paste0(plotloc, "/","yuLIRSFdna FP - chromosome segplot.png"))
include_graphics(paste0(plotloc, "/","yuRERFdna FP - chromosome segplot.png"))
include_graphics(paste0(plotloc, "/","yuRIRSFdna FP - chromosome segplot.png"))
include_graphics(paste0(plotloc, "/","yuRKTGFdna FP - chromosome segplot.png"))
include_graphics(paste0(plotloc, "/","yuRKTMFdna FP - chromosome segplot.png"))
include_graphics(paste0(plotloc, "/","yuRKTW1Fdna FP - chromosome segplot.png"))
include_graphics(paste0(plotloc, "/","yuTSFdna FP - chromosome segplot.png"))
```
- Yucca left inguinal FP, signal = very noisy
- Yucca right eye FP, signal = very noisy
- Yucca kidney FP (#1-3), signal = very noisy
- Yucca tail FP (#1-3), signal = very noisy

"Though the majority of samples, particularly Yuccaâ€™s, are definitely too noisy for these CNV calls to be trusted. Weâ€™d likely run into a high proportion of false positive hits when intersecting the current cnMOPS calls with gene lists, doing GO term analyses, etc."



